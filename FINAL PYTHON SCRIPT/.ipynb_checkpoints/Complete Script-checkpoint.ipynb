{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from html.parser import HTMLParser\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV as logCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs= True\n",
    "        self.fed = []\n",
    "    def handle_data(self, d):\n",
    "        self.fed.append(d)\n",
    "    def get_data(self):\n",
    "        return ''.join(self.fed)\n",
    "\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()\n",
    "\n",
    "def descrClean(x):\n",
    "    des = strip_tags(x)\n",
    "    return des.lower()\n",
    "\n",
    "# Function to Classify Unit Types\n",
    "def unitType(x, types):\n",
    "    homeType = {    \n",
    "        }\n",
    "    for lst in types:\n",
    "        homeType[lst[0]] = False\n",
    "    \n",
    "    for lst in types:\n",
    "        for w in lst:\n",
    "            if w in x:\n",
    "                return lst[0]\n",
    "    return 'other'\n",
    "\n",
    "\n",
    "def cleanPreprocessData(train, test):\n",
    "    print('Cleaning...')\n",
    "    df = train\n",
    "    test['test'] = True\n",
    "\n",
    "    #Merge the two files to clean and comput interaction terms.\n",
    "    df = df.append(test)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df['test'].fillna(False, inplace=True)\n",
    "\n",
    "    #Clean the column names for regressions and ML Models\n",
    "    df.columns = [c.replace(' ', '_') for c in df.columns]\n",
    "    df.columns = [c.replace('-', '_') for c in df.columns]\n",
    "    df.columns = [c.replace('/', '_') for c in df.columns]\n",
    "\n",
    "    #Confirm types for columns with numbers\n",
    "    df['bedrooms'] = df['bedrooms'].apply(float)\n",
    "    df['bedrooms'].fillna(0, inplace=True)\n",
    "    df['bathrooms'].fillna(0, inplace=True)\n",
    "\n",
    "    #Drop meaningless columns in data\n",
    "    df.drop(['index', 'level_0'], axis=1, inplace=True)\n",
    "\n",
    "    #Map Interest levels to values for OLS Regression\n",
    "    df['interestVal'] = df['interest_level'].map({'high': 1, 'medium': 0.5, 'low':0})\n",
    "\n",
    "    #Clean the HTML from descriptions to allow for NLP\n",
    "    df['description'] = df['description'].apply(descrClean)\n",
    "\n",
    "    # Aggregate to create one laundry in building column that isn't case sensitive\n",
    "    df['laundry_in_building'] = df.apply(lambda row: row['Laundry_in_Building'] or row['Laundry_In_Building'], axis=1)\n",
    "\n",
    "    # Drop old laundry in building columns\n",
    "    df = df.drop(['Laundry_in_Building', 'Laundry_In_Building'], axis=1)\n",
    "\n",
    "    cleanedDf = df\n",
    "\n",
    "    print('Cleaning Complete. Processing descriptions to determine type...')\n",
    "\n",
    "    # To determine the type of rental unit, we conduct a basic NLP\n",
    "    # Define basic unit types\n",
    "    apt = ['apartment', 'apt']\n",
    "    condo = ['condominium', 'condo']\n",
    "    walkUp = ['walk_up', 'walk-up', 'walkup', 'walk up']\n",
    "    studio = ['studio']\n",
    "    ph = ['ph', 'penhouse']\n",
    "    townhome = ['townhome', 'duplex', 'townhouse']\n",
    "    loft = ['loft']\n",
    "\n",
    "    types = [apt, condo, walkUp, studio, ph, townhome, loft]\n",
    "\n",
    "    #Determine rental type\n",
    "    df['type'] = df['description'].apply(lambda x : unitType(x, types)) \n",
    "\n",
    "    #Determine if a type has been found\n",
    "    df['foundType'] = ~df['type'].str.contains('other') \n",
    "\n",
    "    #Create binary dummy columns for each type\n",
    "    df = pd.concat([df, pd.get_dummies(df['type'])], axis=1) \n",
    "\n",
    "    #Combine and drop the two loft column\n",
    "    df['loft'].fillna(False, inplace=True)\n",
    "    df['loft'] = df[['loft', 'Loft']].apply(lambda row : row['loft'] or row['Loft'], axis=1)\n",
    "    df.drop('Loft', axis=1, inplace=True)\n",
    "\n",
    "    cleanedTyped = df\n",
    "\n",
    "    print('Typing Complete. Generating Interaction Terms...')\n",
    "\n",
    "    # Generate interaction terms to find differentiators\n",
    "    # Luxury Score Term - higher the score means the more luxury items included\n",
    "    df['lux_score'] = (df['Exclusive'] + df['Doorman'] + df['Outdoor_Space'] + \n",
    "                        df['New_Construction'] + df['Roof_Deck'] + df['Fitness_Center'] + \n",
    "                        df['Swimming_Pool'] + df['Elevator'] + df['Laundry_in_Unit'] + \n",
    "                        df['Hardwood_Floors']) / 10\n",
    "\n",
    "    #Group data by buildings and agents to determine expected interest -----MAGIC FEATURE-----\n",
    "    agentGroup = df.groupby(['manager_id']).mean()\n",
    "    buildingGroup = df.groupby(['building_id', 'manager_id']).mean()\n",
    "\n",
    "    buildingAvg = buildingGroup[['interestVal']]\n",
    "    buildingAvg.columns = ['prob_interest_building']\n",
    "    buildingAvg.reset_index(inplace=True)\n",
    "\n",
    "    managerAvg = agentGroup[['interestVal']]\n",
    "    managerAvg.columns = ['prob_interest_manager']\n",
    "    managerAvg.reset_index(inplace=True)\n",
    "\n",
    "    #Merge back to original DF\n",
    "    df = df.merge(managerAvg, on='manager_id', how='left')\n",
    "    df = df.merge(buildingAvg, on=['building_id', 'manager_id'], how='left')\n",
    "\n",
    "    #Compute expected interest by building and manager\n",
    "    df['prob_buildManager'] = (df['prob_interest_building']+df['prob_interest_manager'])/2\n",
    "\n",
    "    #Count rooms and determine price per room\n",
    "    df['rooms'] = df['bedrooms']+df['bathrooms']\n",
    "    df['price_per_room'] = df['price']/df['rooms']\n",
    "\n",
    "    # Number of Luxury Features Term\n",
    "    df['num_luxury'] = (df['Exclusive'] + df['Doorman'] + df['Outdoor_Space'] + df['New_Construction'] + df['Roof_Deck'] + df['Fitness_Center'] + df['Swimming_Pool'] + df['Elevator'] + df['Laundry_in_Unit'] + df['Hardwood_Floors'])\n",
    "\n",
    "    # Number of Features per Listing\n",
    "    df['num_features'] = df['features'].apply(len)\n",
    "\n",
    "    # ADA compatible interaction term\n",
    "    # 1 if both elevator and wheelchair access, 0 if one or neither are included\n",
    "    df['ada'] = df['Elevator'] * df['Wheelchair_Access']\n",
    "\n",
    "    # Create transformed term that creates a score for outdoor spaces\n",
    "    # Higher the score, the more of these features are included\n",
    "    df['outdoor_score'] = (df['Outdoor_Space'] + df['Balcony'] + df['Common_Outdoor_Space'] \n",
    "                           + df['Garden_Patio'] + df['Roof_Deck'] + df['Terrace']) / 6\n",
    "\n",
    "    # Create interaction term for fitness oriented\n",
    "    # 1 if both swimming pool and fitness center are included, 0 if one or neither included\n",
    "    df['fitness_oriented'] = df['Fitness_Center'] * df['Swimming_Pool']\n",
    "\n",
    "    # Create interaction term for doorman/exclusive\n",
    "    # 1 if both are included, 0 if one or neither are included\n",
    "    df['door_excl'] = df['Doorman'] * df['Exclusive']\n",
    "\n",
    "    # Create interaction term for cats and dogs allowed\n",
    "    # 1 if both are allowed, 0 if one or neither are allowed\n",
    "    df['pets_allowed'] = df['Cats_Allowed'] * df['Dogs_Allowed']\n",
    "\n",
    "    #Compute price per feature and price per luxury feature. \n",
    "    #If no features exist, the value is empty\n",
    "    df['price_per_feature'] = df['price']/df['num_features']\n",
    "    df['price_per_feature'].replace(np.inf, np.nan, inplace=True)\n",
    "\n",
    "    df['price_per_num_lux'] = df['price']/df['num_luxury']\n",
    "    df['price_per_num_lux'].replace(np.inf, np.nan, inplace=True)\n",
    "\n",
    "    #Determine expected prices by type of unit\n",
    "    g1 = df.groupby(['type']).mean()\n",
    "    g1.reset_index(inplace=True)\n",
    "\n",
    "    #Columns we wish to average\n",
    "    avgs = g1[['type','lux_score', 'num_features', \n",
    "               'num_luxury','outdoor_score', 'price_per_num_lux', \n",
    "               'price_per_feature']]\n",
    "\n",
    "    pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "    #Rename columns and merge back to original DF\n",
    "    avgs.columns = ['avg_'+x for x in avgs]\n",
    "    avgs.rename(columns={'avg_type':'type'}, inplace=True)\n",
    "    df = pd.merge(df, avgs, on='type')\n",
    "\n",
    "    #If no price was found, set the price for the column as average to avoid skewing the data\n",
    "    df['price_per_num_lux'].fillna(df['avg_price_per_num_lux'], inplace=True)\n",
    "    df['outdoor_score'].fillna(df['avg_outdoor_score'], inplace=True)\n",
    "    df['lux_score'].fillna(df['avg_lux_score'], inplace=True)\n",
    "    df['price_per_feature'].fillna(df['avg_price_per_feature'], inplace=True)\n",
    "\n",
    "    df['price_lux_ratio'] = df['price_per_num_lux']/df['avg_price_per_num_lux']\n",
    "    df['outdoor_ratio'] = df['outdoor_score']/df['avg_outdoor_score']\n",
    "    df['lux_ratio'] = df['lux_score']/df['avg_lux_score']\n",
    "    df['price_feature_ratio'] = df['price_per_feature']/df['avg_price_per_feature']\n",
    "\n",
    "\n",
    "    #Compute the number of photos included in the listing\n",
    "    df['numPhotos'] = df['photos'].apply(len)\n",
    "\n",
    "    #Listing id is an arbitrary int label assined to each listing. not useful for classification\n",
    "    df.drop(['listing_id'], axis=1, inplace=True)\n",
    "\n",
    "    #Output new training and testing datasets\n",
    "    train = pd.DataFrame(df[df['test']==False].dropna())\n",
    "    train.reset_index(drop=True, inplace=True)\n",
    "    train.drop('test', inplace=True, axis=1)\n",
    "    \n",
    "    test = pd.DataFrame(df[df['test']])\n",
    "    test.reset_index(drop=True, inplace=True)\n",
    "    test.drop('test', inplace=True, axis=1)\n",
    "\n",
    "    train.to_json('./cleaned/train.json')\n",
    "    test.to_json('./cleaned/test.json')\n",
    "\n",
    "    return cleanedDf, cleanedTyped, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runModel():\n",
    "    \n",
    "    train = pd.read_json('./cleaned/train.json')\n",
    "    test = pd.read_json('./cleaned/test.json')\n",
    "    \n",
    "    #Determine the columns with which to run an OLS, exclude the indicator column\n",
    "    data = train.drop('interestVal', axis=1).select_dtypes(exclude=['object'])\n",
    "\n",
    "    #join columns to build to equation\n",
    "    equation = ('+').join(data.columns)\n",
    "\n",
    "    #run the OLS to determine significant columns\n",
    "    model = smf.ols('interestVal~'+equation, data=train).fit()\n",
    "\n",
    "    #make a DF of significant features\n",
    "    sig_features = pd.DataFrame(model.pvalues, index=data.columns, columns={'P_Value'})\n",
    "\n",
    "    sigCols = sig_features[sig_features['P_Value']<.1].index.values\n",
    "    print('The data has {} significant columns'.format(len(sigCols)))\n",
    "    print('The significant columns are: ')\n",
    "    print(sig_features[sig_features['P_Value']<.1])\n",
    "    print()\n",
    "\n",
    "    sigCols = np.append(sigCols, 'interest_level')\n",
    "\n",
    "    #Create a simplified df with only the significant columns\n",
    "    validLogTest = test[~pd.isnull(test['prob_interest_building'])]\n",
    "    \n",
    "    simpleTrain = train[sigCols]\n",
    "    simpleTest = validLogTest[sigCols]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(simpleTrain.drop('interest_level',axis=1),\n",
    "                                                    simpleTrain['interest_level'], test_size=0.33, \n",
    "                                                    random_state=42)\n",
    "    \n",
    "    print('Running Logistic Regression on best data...')\n",
    "    \n",
    "    logReg = logCV(cv=10)\n",
    "    logReg.fit(X_train, y_train)\n",
    "    print(classification_report(logReg.predict(X_test), y_test))\n",
    "\n",
    "    logReg.fit(simpleTrain.drop('interest_level', axis=1), simpleTrain['interest_level'])\n",
    "    logPreds = logReg.predict(simpleTest.drop('interest_level', axis=1))\n",
    "\n",
    "    validLogTest['interest_level'] = logPreds\n",
    "    \n",
    "    print('Running SVM on lower quality data...')\n",
    "    \n",
    "    #Because some of the data is still unknown, we have to use an SVM to classify about 48% of the test data\n",
    "    svmTest = test[pd.isnull(test['prob_interest_building'])]\n",
    "    \n",
    "    #______________SVM____________#\n",
    "    \n",
    "    return validLogTest['interest_level'], test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning...\n",
      "Cleaning Complete. Processing descriptions to determine type...\n",
      "Typing Complete. Generating Interaction Terms...\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_json('./raw_data/train_data.json')\n",
    "test = pd.read_json('./raw_data/test_data.json')\n",
    "\n",
    "cleanedDF, cleanedTyped, train, test = cleanPreprocessData(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data has 7 significant columns\n",
      "The significant columns are: \n",
      "                         P_Value\n",
      "Common_Outdoor_Space    0.032009\n",
      "No_Fee                  0.000164\n",
      "bathrooms               0.025488\n",
      "prob_buildManager       0.000000\n",
      "prob_interest_building  0.000000\n",
      "prob_interest_manager   0.000000\n",
      "rooms                   0.008104\n",
      "\n",
      "Running Logistic Regression on best data...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       high       0.83      0.80      0.81      1057\n",
      "        low       0.98      0.92      0.95     10311\n",
      "     medium       0.70      0.89      0.78      2465\n",
      "\n",
      "avg / total       0.92      0.91      0.91     13833\n",
      "\n",
      "Running SVM on lower quality data...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'interest_leve'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/Users/Braden/anaconda/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2441\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2442\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2443\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5280)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5126)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20523)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20477)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'interest_leve'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-c595797da12e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-44-0e34e2ead17a>\u001b[0m in \u001b[0;36mrunModel\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m#______________SVM____________#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalidLogTest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'interest_leve'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/Braden/anaconda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1962\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1964\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1966\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Braden/anaconda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1969\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1970\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1971\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1973\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Braden/anaconda/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1643\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1645\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Braden/anaconda/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3589\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3590\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3591\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3592\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Braden/anaconda/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2442\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2443\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2444\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2446\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5280)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5126)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20523)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20477)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'interest_leve'"
     ]
    }
   ],
   "source": [
    "preds, test = runModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
