{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file explores the results of the data processed using Natural Language Processing techniques that was used to classify listings based on the type of home. In this file, we first split up the dataset (only the subset that was successfully classified) into many smaller datasets based on type (effectively partitioning the data), and then train a Random Forest Classifier on each partition. From the results of our preliminary work on trees (see: ), a Random Forest Classifier was used because it yielded the highest classification accuracy (roughtly .72). The classification accuracy for each individually fit trees was then compared to two separate Random Forest Classifier models. The first model the partitioned trees were compared to is a basic Random Forest Classifier trained without 'typed' data. The second is a Random Forest Classifier trained with all the 'typed' data (binary columns of type). The results of partitioned models were then compared, to see if a partitioned Random Forest performed better than the general, all inclusive random forest. We were trying to answer the question: are the features that are predictive of listing interest different for a different type of listing (apartment, penthouse, loft, etc)?\n",
    "\n",
    "We answered this question by testing the two all-inclusive trees against the known typed data and comparing these trees to the performance of the typed-exclusive trees on their respective typed listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "import requests as re\n",
    "\n",
    "sns.set_context('poster')\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "\n",
    "#Trees\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Preprocessing packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer #One hot encoding\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "#Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "#Metrics\n",
    "from sklearn.metrics import confusion_matrix, auc, roc_curve, classification_report\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image \n",
    "\n",
    "#Bootstrap\n",
    "from sklearn.utils import resample\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1: Tree Exploration on Typed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train = pd.read_json(\"typedData/train_typed.json\")\n",
    "#test = pd.read_json(\"typedData/testX.json\")\n",
    "data = pd.read_json(\"rawData/cleanedTyped.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split data by type\n",
    "train, test, y_train, y_test = train_test_split(data, data['interest_level'], test_size=0.3, random_state=42)\n",
    "\n",
    "train_orig = train.copy()\n",
    "\n",
    "y_train = train['interest_level']\n",
    "\n",
    "y_train_stud = train[train['studio'] == 1]['interest_level']\n",
    "y_train_town = train[train['townhome'] == 1]['interest_level']\n",
    "y_train_appt = train[train['apartment'] == 1]['interest_level']\n",
    "y_train_loft = train[train['loft'] == 1]['interest_level']\n",
    "y_train_cond = train[train['condominium'] == 1]['interest_level']\n",
    "y_train_ph = train[train['ph'] == 1]['interest_level']\n",
    "y_train_walk = train[train['walk_up'] == 1]['interest_level']\n",
    "\n",
    "\n",
    "train = train.drop(['interest_level','interestVal','description','type','display_address','created','building_id','features', 'manager_id', 'street_address'], axis=1)\n",
    "\n",
    "x_train_stud = train[train['studio'] == 1]\n",
    "x_train_town = train[train['townhome'] == 1]\n",
    "x_train_appt = train[train['apartment'] == 1]\n",
    "x_train_loft = train[train['loft'] == 1]\n",
    "x_train_cond = train[train['condominium'] == 1]\n",
    "x_train_ph = train[train['ph'] == 1]\n",
    "x_train_walk = train[train['walk_up'] == 1]\n",
    "\n",
    "# Tree for studio, townhome, apartment, condominium, loft, pd, walk up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the test data by type\n",
    "\n",
    "y_test_stud = test[test['studio'] == 1]['interest_level']\n",
    "y_test_town = test[test['townhome'] == 1]['interest_level']\n",
    "y_test_appt = test[test['apartment'] == 1]['interest_level']\n",
    "y_test_loft = test[test['loft'] == 1]['interest_level']\n",
    "y_test_cond = test[test['condominium'] == 1]['interest_level']\n",
    "y_test_ph = test[test['ph'] == 1]['interest_level']\n",
    "y_test_walk = test[test['walk_up'] == 1]['interest_level']\n",
    "\n",
    "y_test = test['interest_level']\n",
    "test = test.drop(['interest_level','interestVal','type','description','display_address','created','building_id','features', 'manager_id','street_address'], axis=1)\n",
    "\n",
    "\n",
    "x_test_stud = test[test['studio'] == 1]\n",
    "x_test_town = test[test['townhome'] == 1]\n",
    "x_test_appt = test[test['apartment'] == 1]\n",
    "x_test_loft = test[test['loft'] == 1]\n",
    "x_test_cond = test[test['condominium'] == 1]\n",
    "x_test_ph = test[test['ph'] == 1]\n",
    "x_test_walk = test[test['walk_up'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are training 7 different partitioned trees depending on the type label of the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score for a tree trained with studio listings only (and predicted for studio listings) is: 0.6727748691099477 \n",
      "0.691932864104\n"
     ]
    }
   ],
   "source": [
    "# Random Forest on Studio Listings\n",
    "sqrt_forest = RandomForestClassifier(warm_start=True, \n",
    "                             oob_score=True,\n",
    "                             max_features=\"sqrt\",\n",
    "                             random_state = 1)\n",
    "\n",
    "sqrt_forest.set_params(n_estimators=170)\n",
    "sqrt_forest.fit(x_train_stud, y_train_stud)\n",
    "\n",
    "print(\"The score for a tree trained with studio listings only (and predicted for studio listings) is: {} \".format(sqrt_forest.score(x_test_stud, y_test_stud)))\n",
    "print(sqrt_forest.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score for a tree trained and tested with townhouse listings only is: 0.7192982456140351 \n",
      "0.703832752613\n"
     ]
    }
   ],
   "source": [
    "# Townhouse listings only\n",
    "sqrt_forest = RandomForestClassifier(warm_start=True, \n",
    "                             oob_score=True,\n",
    "                             max_features=\"sqrt\",\n",
    "                             random_state = 1)\n",
    "\n",
    "sqrt_forest.set_params(n_estimators=170)\n",
    "sqrt_forest.fit(x_train_town, y_train_town)\n",
    "\n",
    "print(\"The score for a tree trained and tested with townhouse listings only is: {} \".format(sqrt_forest.score(x_test_town, y_test_town)))\n",
    "print(sqrt_forest.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score for a tree trained and tested with apartment listings only is: 0.7049906090689563\n",
      "0.690433783396\n"
     ]
    }
   ],
   "source": [
    "# Apartment Listings Only\n",
    "sqrt_forest = RandomForestClassifier(warm_start=True, \n",
    "                             oob_score=True,\n",
    "                             max_features=\"sqrt\",\n",
    "                             random_state = 1)\n",
    "\n",
    "sqrt_forest.set_params(n_estimators=170)\n",
    "sqrt_forest.fit(x_train_appt, y_train_appt)\n",
    "\n",
    "print(\"The score for a tree trained and tested with apartment listings only is: {}\".format(sqrt_forest.score(x_test_appt, y_test_appt)))\n",
    "print(sqrt_forest.oob_score_)\n",
    "\n",
    "\n",
    "# Tree for studio, townhome, apartment, condominium, loft, pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score for a tree trained and tested with condominium listings only is: 0.7384615384615385.\n",
      "0.667938931298\n"
     ]
    }
   ],
   "source": [
    "# Condominium Listings Only\n",
    "sqrt_forest = RandomForestClassifier(warm_start=True, \n",
    "                             oob_score=True,\n",
    "                             max_features=\"sqrt\",\n",
    "                             random_state = 1)\n",
    "\n",
    "sqrt_forest.set_params(n_estimators=170)\n",
    "sqrt_forest.fit(x_train_cond, y_train_cond)\n",
    "\n",
    "print(\"The score for a tree trained and tested with condominium listings only is: {}.\".format(sqrt_forest.score(x_test_cond, y_test_cond)))\n",
    "print(sqrt_forest.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score for a tree trained and tested with loft listings only is: 0.652317880794702.\n",
      "0.672740524781\n"
     ]
    }
   ],
   "source": [
    "# Loft listings only\n",
    "sqrt_forest = RandomForestClassifier(warm_start=True, \n",
    "                             oob_score=True,\n",
    "                             max_features=\"sqrt\",\n",
    "                             random_state = 1)\n",
    "\n",
    "sqrt_forest.set_params(n_estimators=170)\n",
    "sqrt_forest.fit(x_train_loft, y_train_loft)\n",
    "print(\"The score for a tree trained and tested with loft listings only is: {}.\".format(sqrt_forest.score(x_test_loft, y_test_loft)))\n",
    "print(sqrt_forest.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score for a tree trained and tested with penthouse listings only is: 0.6415929203539823.\n",
      "0.67941712204\n"
     ]
    }
   ],
   "source": [
    "# Penthouse listings only\n",
    "sqrt_forest = RandomForestClassifier(warm_start=True, \n",
    "                             oob_score=True,\n",
    "                             max_features=\"sqrt\",\n",
    "                             random_state = 1)\n",
    "\n",
    "sqrt_forest.set_params(n_estimators=170)\n",
    "sqrt_forest.fit(x_train_ph, y_train_ph)\n",
    "\n",
    "print(\"The score for a tree trained and tested with penthouse listings only is: {}.\".format(sqrt_forest.score(x_test_ph, y_test_ph)))\n",
    "print(sqrt_forest.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score for a tree trained and tested with walk-in listings only is: 0.6666666666666666.\n",
      "0.702702702703\n"
     ]
    }
   ],
   "source": [
    "# Walk in listings only\n",
    "sqrt_forest = RandomForestClassifier(warm_start=True, \n",
    "                             oob_score=True,\n",
    "                             max_features=\"sqrt\",\n",
    "                             random_state = 1)\n",
    "\n",
    "sqrt_forest.set_params(n_estimators=170)\n",
    "sqrt_forest.fit(x_train_walk, y_train_walk)\n",
    "\n",
    "print(\"The score for a tree trained and tested with walk-in listings only is: {}.\".format(sqrt_forest.score(x_test_walk, y_test_walk)))\n",
    "print(sqrt_forest.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1088\n",
      "0.05499671435070515\n",
      "156\n",
      "28\n",
      "988\n"
     ]
    }
   ],
   "source": [
    "# A Digression: it was observed that we had two \"loft\" columns in the graph. \n",
    "# Differences were studied here and subsequently disregarded.\n",
    "loft_descrepancies = train['loft'] == train['Loft']\n",
    "\n",
    "num_desc = [True for t in loft_descrepancies if t == False]\n",
    "print(len(num_desc))\n",
    "print(len(num_desc)/len(train['loft']))\n",
    "\n",
    "brad_loft_num = train[train['loft'] == 1]\n",
    "print(len(brad_loft_num))\n",
    "print(len(brad_loft_num[brad_loft_num['Loft'] == 1]))\n",
    "\n",
    "given_loft_num = len(train[train['Loft'] == 1])\n",
    "\n",
    "print(given_loft_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to train a tree without any typed data and then compare this trees performance on the true typed data to the typed-specific trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_untyped = train.drop(['loft','ph','condominium','apartment','townhome','studio','walk_up'],axis=1)\n",
    "test_untyped = test.drop(['loft','ph','condominium','apartment','townhome','studio','walk_up'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.720976463104\n",
      "0.71157385318\n"
     ]
    }
   ],
   "source": [
    "# Tree WITHOUT type labels\n",
    "sqrt_forest = RandomForestClassifier(warm_start=True, \n",
    "                             oob_score=True,\n",
    "                             max_features=\"sqrt\",\n",
    "                             random_state = 1)\n",
    "\n",
    "sqrt_forest.set_params(n_estimators=170)\n",
    "sqrt_forest.fit(train_untyped, y_train)\n",
    "\n",
    "print(sqrt_forest.score(test_untyped,y_test))\n",
    "print(sqrt_forest.oob_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are training a tree on the typed data and comparing this tree's performance to the typed-specific trees, as well as to the tree trained on untyped data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.720499363868\n",
      "0.712289550815\n"
     ]
    }
   ],
   "source": [
    "# single tree including type labels\n",
    "gen_forest = RandomForestClassifier(warm_start=True, \n",
    "                             oob_score=True,\n",
    "                             max_features=\"sqrt\",\n",
    "                             random_state = 1)\n",
    "\n",
    "gen_forest.set_params(n_estimators=170)\n",
    "gen_forest.fit(train, y_train)\n",
    "\n",
    "print(gen_forest.score(test,y_test))\n",
    "print(gen_forest.oob_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, it seems that whether the data was typed or not, the tree performed very similarly..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The true indicator is seeing the difference in score for the \n",
    "# combined typed tree and the partitioned typed tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.692408376963\n"
     ]
    }
   ],
   "source": [
    "#Partitioned Studio score: 0.6711595866819747 \n",
    "print(gen_forest.score(x_test_stud,y_test_stud))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.710526315789\n"
     ]
    }
   ],
   "source": [
    "#Partitioned Townhome score: 0.71875 \n",
    "print(gen_forest.score(x_test_town,y_test_town))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.706198014489\n"
     ]
    }
   ],
   "source": [
    "#Partitioned apartment score: 0.7007227734901385\n",
    "print(gen_forest.score(x_test_appt, y_test_appt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.784615384615\n"
     ]
    }
   ],
   "source": [
    "#Partitioned condominium score: 0.742647058823529\n",
    "print(gen_forest.score(x_test_cond, y_test_cond))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.662251655629\n"
     ]
    }
   ],
   "source": [
    "# Partitioned Loft score: 0.6470588235294118\n",
    "print(gen_forest.score(x_test_loft, y_test_loft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.663716814159\n"
     ]
    }
   ],
   "source": [
    "# Partitioned Penthouse score: 0.6334661354581673\n",
    "print(gen_forest.score(x_test_ph, y_test_ph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.691358024691\n"
     ]
    }
   ],
   "source": [
    "# Partitioned Walk In score: 0.66666\n",
    "print(gen_forest.score(x_test_walk, y_test_walk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Notable changes: Condominium increased with general tree, Loft increased with general tree\n",
    "# Minor changes: penthouse, loft, apartment did better on general tree by a very small amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Conclusion: housing type does not seem to play a significant role in creating a better model to predict interest level, nor does it seem to play a significant role in interest level at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2: Attempting to Reduce Number of Listings Classified as Low \n",
    "\n",
    "While exploring the data, our group noticed that the models have a strong tendency to classify a listing as low, due to the fact that \"low\" interest levels dominate this dataset. Below we look into reclassifying the labeled data into \"high\" and \"other\" and then into \"low' and \"other\". And training two different models on each. This might give us a better glimpse into the data and allow us to find a model that has fewer false positives for \"low\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_json(\"rawData/cleanedTyped.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "low       29147\n",
       "medium     9491\n",
       "high       3280\n",
       "Name: interest_level, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['interest_level'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Define new columns in the data for \"high\" and \"other\" and low and other, \n",
    "# delineating interest level by \"low_other\" and \"hi_other\". and then dropping all other labels.\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.3, random_state=42)\n",
    "\n",
    "train['hi_other'] = [\"high\" if interest == \"high\" else \"other\" for interest in train['interest_level']]\n",
    "train['low_other'] = [\"low\" if interest == \"low\" else \"other\" for interest in train['interest_level']]\n",
    "\n",
    "hi_other = train['hi_other']\n",
    "low_other = train['low_other']\n",
    "\n",
    "train_ = train.drop(['interest_level','interestVal','type','hi_other','low_other','description','display_address','created','building_id','features', 'manager_id', 'street_address'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "test['hi_other'] = [\"high\" if interest == \"high\" else \"other\" for interest in test['interest_level']]\n",
    "test['low_other'] = [\"low\" if interest == \"low\" else \"other\" for interest in test['interest_level']]\n",
    "\n",
    "hi_other_t = test['hi_other']\n",
    "low_other_t = test['low_other']\n",
    "\n",
    "test_ = test.drop(['interest_level','interestVal','type','hi_other','low_other','description','display_address','created','building_id','features', 'manager_id', 'street_address'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first tree we fit is a tree trained with \"high\" interest and \"other\" interest. As you can see below, it still has very poor scores for \"high\" listings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92183524173\n",
      "0.923829323155\n"
     ]
    }
   ],
   "source": [
    "# single tree including type labels\n",
    "gen_forest = RandomForestClassifier(warm_start=True, \n",
    "                             oob_score=True,\n",
    "                             max_features=\"sqrt\",\n",
    "                             random_state = 1)\n",
    "\n",
    "gen_forest.set_params(n_estimators=170)\n",
    "gen_forest.fit(train_, hi_other)\n",
    "\n",
    "print(gen_forest.score(test_,hi_other_t))\n",
    "print(gen_forest.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "other    11574\n",
      "high      1002\n",
      "Name: hi_other, dtype: int64\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       high       0.53      0.16      0.25      1002\n",
      "      other       0.93      0.99      0.96     11574\n",
      "\n",
      "avg / total       0.90      0.92      0.90     12576\n",
      "\n",
      "[[  161   841]\n",
      " [  142 11432]]\n"
     ]
    }
   ],
   "source": [
    "print(hi_other_t.value_counts())\n",
    "print(classification_report(hi_other_t,gen_forest.predict(test_)))\n",
    "print(confusion_matrix(hi_other_t,gen_forest.predict(test_),labels=['high','other']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the low-other classified tree. This method did not help in creating a model that classified fewer 'low' listings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.770038167939\n",
      "0.761809010974\n",
      "['low' 'other' 'low' ..., 'low' 'low' 'other']\n"
     ]
    }
   ],
   "source": [
    "# single tree including type labels\n",
    "gen_forest = RandomForestClassifier(warm_start=True, \n",
    "                             oob_score=True,\n",
    "                             max_features=\"sqrt\",\n",
    "                             random_state = 1)\n",
    "\n",
    "gen_forest.set_params(n_estimators=170)\n",
    "gen_forest.fit(train_, low_other)\n",
    "predicted1 = gen_forest.predict(test_)\n",
    "\n",
    "\n",
    "print(gen_forest.score(test_,low_other_t))\n",
    "print(gen_forest.oob_score_)\n",
    "print(predicted1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low      8780\n",
      "other    3796\n",
      "Name: low_other, dtype: int64\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        low       0.80      0.90      0.85      8780\n",
      "      other       0.67      0.47      0.55      3796\n",
      "\n",
      "avg / total       0.76      0.77      0.76     12576\n",
      "\n",
      "[[7907  873]\n",
      " [2019 1777]]\n"
     ]
    }
   ],
   "source": [
    "print(low_other_t.value_counts())\n",
    "print(classification_report(low_other_t,gen_forest.predict(test_)))\n",
    "print(confusion_matrix(low_other_t,gen_forest.predict(test_),labels=['low','other']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "A potential next step following this method could be to then take, from the results of the low-other model, pass the labels classified as \"other\" into the high-other tree and re-create the three classes by predicting all \"other\" results from the high-other tree as medium. This idea was not pursued because the low-other tree still vastly overpredicted the number of low trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
